# End-to-End-LLM-Based-Medical-chatbot-RAG
This is End to End Rag project


# ğŸ©º End-to-End LLM-Based Medical Chatbot using RAG

This project is an end-to-end Medical Question Answering Chatbot built using Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG).  
The system generates accurate and context-aware medical responses by grounding LLM outputs with information retrieved from a medical knowledge base.

---

## ğŸ“Œ Project Motivation

Large Language Models can generate fluent responses, but in sensitive domains like healthcare they may hallucinate or provide unreliable information.  
To address this, I implemented a Retrieval-Augmented Generation (RAG) architecture where relevant medical documents are retrieved first and then passed as context to the LLM for response generation.

This approach improves:
- Factual accuracy  
- Domain relevance  
- Trustworthiness of responses  

---

## ğŸ§  Architecture Overview

User Query  
â†’ Flask API  
â†’ LangChain RAG Pipeline  
â†’ Query Embedding  
â†’ Semantic Search using Pinecone  
â†’ Context Injection into LLM  
â†’ Final Medical Response  

---

## ğŸ› ï¸ Tech Stack

- Language Model: OpenAI GPT  
- RAG Framework: LangChain  
- Vector Database: Pinecone  
- Backend API: Flask  
- Embeddings: Sentence Transformers  
- Document Processing: PyPDF  
- Deployment: AWS EC2  
- Secrets Management: Environment Variables (.env)

---

## âœ¨ Key Features

- Semantic search over medical documents using vector embeddings  
- Retrieval-Augmented Generation to reduce hallucinations  
- Domain-specific medical knowledge base  
- Secure API key and credential management  
- Deployable both locally and on AWS  

---

## ğŸ” Conversational RAG with Memory

This project has been extended from a basic knowledge-based RAG system
to a conversational RAG architecture using LangChain's
ConversationBufferMemory.

### Key Features
- Maintains full chat history across turns
- Supports follow-up medical questions
- Uses ConversationalRetrievalChain
- Non-agentic, deterministic control flow

### Architecture
User â†’ Flask API â†’ Conversational Retrieval Chain
â†’ (Conversation Buffer Memory + Pinecone Retriever + LLM)
â†’ Context-aware medical response

-----------
## ğŸ¤– Agentic RAG Architecture

This project has been upgraded from a conversational RAG system to an
Agentic RAG architecture using LangChain agents.

### Key Enhancements
- ReAct-style reasoning loop
- LLM-driven decision making
- Retriever exposed as a tool
- Conversation memory preserved
- Conditional medical knowledge retrieval

### Architecture
User â†’ Flask API â†’ LLM Agent
â†’ (Conversation Memory + Pinecone Retriever Tool)
â†’ Grounded Medical Response



â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        User          â”‚
â”‚ (Medical Question)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Flask API             â”‚
â”‚  (Inference Endpoint)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        LLM Agent (LangChain Agent)         â”‚
â”‚------------------------------------------â”‚
â”‚  â€¢ ReAct Reasoning Loop                   â”‚
â”‚  â€¢ LLM-driven decision making             â”‚
â”‚  â€¢ Decides whether to:                    â”‚
â”‚      - Retrieve medical knowledge         â”‚
â”‚      - Refine the query                   â”‚
â”‚      - Answer directly                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚               â”‚
        â”‚               â”‚
        â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Conversation     â”‚   â”‚   Retriever Tool        â”‚
â”‚ Memory           â”‚   â”‚ (Pinecone Vector DB)    â”‚
â”‚-----------------â”‚   â”‚------------------------â”‚
â”‚ â€¢ Buffer Memory  â”‚   â”‚ â€¢ Medical embeddings   â”‚
â”‚ â€¢ Chat history   â”‚   â”‚ â€¢ Semantic similarity  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Retrieved Medical Context â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚      LLM Generation       â”‚
              â”‚ (Grounded Medical Answer) â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
                   Final Response

